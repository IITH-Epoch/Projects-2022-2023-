{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import Siamese\n",
    "import sklearn.datasets\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss:\n",
    "    def __init__(self, margin = 1):\n",
    "        self.margin = margin\n",
    "\n",
    "    def __call__(self, encodingA, encodingB, label):\n",
    "        euclidean_distance = F.pairwise_distance(encodingA, encodingB)\n",
    "        contrastive_loss = -1\n",
    "        return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calling Siamese Neural Network object from Siamese.py\n",
    "Net = Siamese.SiameseNeuralNetwork()\n",
    "#  Declare the Contrastive Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "#  Declare the Optimizer\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 0.01, weight_decay = 0.005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing the Neural Network\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(Net, (1, 64, 64))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Credit to AT&T Laboratories Cambridge\n",
    "# Fetching the Olivetti DataSet using SKLearn\n",
    "data = sklearn.datasets.fetch_olivetti_faces()\n",
    "# This dataset contains 40 distinct persons with 10 image per person\n",
    "images = data.images\n",
    "labels = data.target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating Pair Dataset as the Siamese Neural Network takes in Pairs of Images for Training\n",
    "\n",
    "def PairedDataset(images, labels) :\n",
    "    classes = np.unique(labels)\n",
    "    # Sort the Indices of Labels According to its respective Class\n",
    "    classes_index = dict()\n",
    "    for label in classes :\n",
    "        classes_index.setdefault(label, [index for index in range(len(labels)) if label == labels[index]])\n",
    "\n",
    "    snn_images = []\n",
    "    snn_labels = []\n",
    "\n",
    "    for index in range(len(images)) :\n",
    "        # Generation of Positive Pair - Containing the Same Person\n",
    "        Positive_Index = classes_index.get(labels[index]) # List of all the Indices related to that particular class\n",
    "        Positive_Image = images[np.random.choice(Positive_Index)]\n",
    "        snn_images.append((images[index], Positive_Image))\n",
    "        snn_labels.append(1) # Target is Put as 2 Classes such that for a Positive Pair it's 1 and 0 for Negative Pair\n",
    "\n",
    "        # Generation of Negative Pair - Containing Different Persons\n",
    "        Negative_Index = np.where(labels != labels[index]) # List of all the Indices that doesn't equal that particular class\n",
    "        Negative_Image = images[np.random.choice(Negative_Index[0])]\n",
    "        snn_images.append((images[index], Negative_Image))\n",
    "        snn_labels.append(0)\n",
    "    return np.array(snn_images), np.array(snn_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
